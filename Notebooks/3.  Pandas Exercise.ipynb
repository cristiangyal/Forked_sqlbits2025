{"cells":[{"cell_type":"markdown","source":["# üßë‚Äçüíº HR Dataset ‚Äì Learner Exercises\n","\n","This notebook is for you to practise basic DataFrame tasks using a sample HR dataset.\n","\n","**What you'll practise:**\n","- Loading and inspecting data\n","- Checking for empty DataFrames\n","- Viewing column names and types\n","- Exploring the shape and previewing rows"],"metadata":{},"id":"d8570e86"},{"cell_type":"markdown","source":["## 1Ô∏è‚É£ Import Libraries"],"metadata":{},"id":"43412117"},{"cell_type":"code","source":["# TODO: Import pandas and numpy\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5c6dffb7"},{"cell_type":"markdown","source":["## 2Ô∏è‚É£ Load the HR Dataset"],"metadata":{},"id":"074fcffe"},{"cell_type":"code","source":["# TODO: Load the CSV file into a DataFrame called df\n","# Hint: Use pd.read_csv() with the correct file path or import from Files using pandas and the three dots to the side of the file\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"51a067d4"},{"cell_type":"markdown","source":["## 3Ô∏è‚É£ Check If DataFrame Is Empty"],"metadata":{},"id":"941e2d16"},{"cell_type":"code","source":["# TODO: Use an if/else block to check if df is empty using df.empty\n","# don't forget the syntax for if, else and indentation\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e4e03a2b"},{"cell_type":"markdown","source":["## 4Ô∏è‚É£ Explore the Columns and Shape"],"metadata":{},"id":"9c297a05"},{"cell_type":"code","source":["# TODO: Use df.columns and df.shape to see structure\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a28eebbc"},{"cell_type":"markdown","source":["## 5Ô∏è‚É£ Preview the Data"],"metadata":{},"id":"032dc8e0"},{"cell_type":"code","source":["# TODO: Show the first few rows using .head()\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"589250c8"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f105ae53-61b9-4864-b4e5-5e1f979f25fd"},{"cell_type":"markdown","source":["## 6Ô∏è‚É£ Check Column Data Types"],"metadata":{},"id":"5ea8979f"},{"cell_type":"code","source":["# TODO: Use df.dtypes to check column data types\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e24c0460"},{"cell_type":"markdown","source":["## üß™ Bonus Challenge ‚Äì Try This!"],"metadata":{},"id":"7e9b7dbe"},{"cell_type":"code","source":["# Can you describe the numeric columns?\n","# Hint: Try using .describe()\n","# Challenge, how would you choose one column, or event two? #Show error with ChatGPT df.describe([\"last_evaluation\"])\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e474be6b"},{"cell_type":"markdown","source":["df[\"last_evaluation\"].describe()"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"622865a7-b32d-46fc-9d5d-8801416180c1"},{"cell_type":"markdown","source":["## üß∞ Data Wranglers ‚Äì Have a Go! 10 mins \n","\n","You've got the tools ‚Äî now it's time to start shaping your data!  \n","Use what you've learned (and your curiosity) to explore the HR dataset further.\n","\n","###### **You can use the Data Wrangler tool to get started and use it to teach you.**\n","\n","üéØ Try these wrangling challenges:\n","\n","- ‚úÖ Remove rows with missing values (`.dropna()`)\n","- ‚úÖ Remove any duplicate records (`.drop_duplicates()`)\n","- ‚úÖ Filter the data to show just one department (`df[df['Departments'] == 'sales']`)\n","- ‚úÖ Group by a category, like `salary`, and calculate something useful\n","- ‚úÖ Be inventive! Try sorting, renaming columns, or creating a new column from existing data\n","\n","üß† There are no wrong answers here ‚Äî just insight waiting to happen.\n","\n","üí¨ When you‚Äôre done, share one insight you found or method you used!\n"],"metadata":{},"id":"b0cb6485"}],"metadata":{"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"kernel_info":{"name":"synapse_pyspark"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"300bf873-d380-4f73-8685-642a0f911bbd"}],"default_lakehouse":"300bf873-d380-4f73-8685-642a0f911bbd","default_lakehouse_name":"PythonIntro","default_lakehouse_workspace_id":"0ab57829-4ee1-4a0a-8678-6b07f7109f8f"}}},"nbformat":4,"nbformat_minor":5}