{"cells":[{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"41ce1cbc-712f-4be0-bf5c-7df8dce7ad32"},{"cell_type":"markdown","source":["## 🧠 Let's Check In!\n","\n","## Go to 👉 [www.menti.com](https://www.menti.com)  \n","## and enter the code: **6247 1541**\n","## \n","## > 💬 Answer the question on screen — your response will appear live!"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b6a6fa85-9671-4ca1-baec-44be6e563079"},{"cell_type":"code","source":["import pandas as pd\n","# Load data into pandas DataFrame from \"/lakehouse/default/Files/HR_file.csv\"\n","df = pd.read_csv(\"/lakehouse/default/Files/HR_file.csv\")\n","display(df)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"b9056c4e-b2df-46e6-a02e-118a02a5d67a"},{"cell_type":"markdown","source":["## 🔢 NumPy: The Powerhouse of Numerical Computing\n","\n","###### NumPy is a powerful library for **efficient numerical computing in Python**.  \n","###### It provides **fast mathematical operations**, **multi-dimensional arrays**, and **integration with other data tools**.\n","###### \n","###### ✅ Why Use NumPy?\n","###### - 🚀 **Efficient Array Handling** – Much faster than Python lists\n","###### - 📏 **Multi-dimensional Array Support** – Supports matrices, tensors, and more\n","###### - 🔢 **Slicing & Indexing** – Similar to lists but more powerful\n","###### - 🤝 **Integrates with**:\n","- ###### **Pandas** – Forms the backbone of DataFrames & Series\n","- ###### **Matplotlib** – Used for visualization in Python\n","- ###### **Scikit-learn** – Essential for Machine Learning\n","###### \n","###### ⏳ Performance Comparison\n","###### - ✅ **Python List Time:** Much slower than NumPy  \n","###### - 🚀 **NumPy Array Time:** Optimized for fast calculations  \n","###### "],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5030684b-cd86-46b0-8c88-f2267d170d5f"},{"cell_type":"markdown","source":["##### 🔢 1. Multi-Dimensional Arrays in NumPy\n","###### ➡️ NumPy makes it easy to work with 2D and 3D arrays — just like Excel sheets or image data."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d92fe41b-5f4b-4930-aaeb-b8663089aaf1"},{"cell_type":"code","source":["import numpy as np\n","\n","# Create a 2D array (like a matrix)\n","matrix = np.array([[1, 2, 3],\n","                   [4, 5, 6],\n","                   [7, 8, 9]])\n","\n","print(\"📐 2D Array:\\n\", matrix)\n","\n","# Access the first row\n","print(\"First row:\", matrix[0])\n","\n","# Access the item at row 2, column 3 (index [1, 2])\n","print(\"Item at (2, 3):\", matrix[1, 2])\n","\n","# Slice a sub-matrix (rows 1–2, columns 1–2) nb the end is exclusive, but the start is inclusive!!\n","print(\"Sub-matrix:\\n\", matrix[0:2, 0:2])\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6f7b6d6a-ee75-43ad-852c-43862f3fc865"},{"cell_type":"markdown","source":["##### 📊 2. Simple Broadcasting (Scalar + Array)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"716fb528-4ac3-4b4e-a654-ee3e7a9c7ab1"},{"cell_type":"code","source":["print(\"📐 matrix:\\n\", matrix)\n","\n","# Add 10 to every element (scalar broadcasting)\n","print(\"Add 10:\\n\", matrix + 10)\n","\n","# Multiply all values by 2\n","print(\"Double values:\\n\", matrix * 2)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ae6b3eae-1f37-4a15-b6c5-cfe68498de3e"},{"cell_type":"markdown","source":["##### 🔄 3. Row-wise Broadcasting"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"30409917-77e6-4bab-a677-412b9dc7d798"},{"cell_type":"code","source":["print(\"📐 matrix:\\n\", matrix)\n","# Add a 1D array to each row (broadcasts across rows)\n","\n","\n","row_add = np.array([1, 10, -1]) # for each row do this to each column\n","print(\"Row-wise add:\\n\", matrix + row_add)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fee973d5-4794-45e1-a6b8-04f1eee82e25"},{"cell_type":"markdown","source":["##### 🔁 4. Column-Wise Broadcasting and `.reshape()`\n","\n","If you want to add values **down the columns** of a 2D matrix (i.e., column-wise),\n","you need a column vector. You can create this by reshaping a 1D array.\n","\n","This ensures the shape lines up for broadcasting:\n","- ✅ Shape of matrix: `(rows, columns)`\n","- ✅ Shape of column vector: `(rows, 1)` – one value per row\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0f8151d4-a019-4964-9dbc-ff00a3524aaf"},{"cell_type":"code","source":["print(\"📐 Matrix:\\n\", matrix)\n","\n","# Create a column vector with one value per row\n","col_add = np.array([10, 20, 30]).reshape(3, 1)\n","\n","print(col_add) # similar to transpose in excel\n","\n","# Broadcast column vector across each row\n","print(\"Column-wise add:\\n\", matrix + col_add)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b972bcc9-8805-4a47-8e69-e89d1d5f3861"},{"cell_type":"markdown","source":["##### 📈 5. Visualise a NumPy Array with Matplotlib\n","###### ➡️ Turn your array into a quick line chart"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4abaf490-d5a9-406b-84bb-82c24e028243"},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Create a simple NumPy array\n","data = np.array([2, 4, 6, 8, 10, 12])\n","\n","# Plot the array\n","plt.plot(data)\n","plt.title(\"📊 Simple Line Plot from NumPy\")\n","plt.xlabel(\"Title\")\n","plt.ylabel(\"Value\")\n","#plt.grid(True)\n","#plt.show()\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0e437272-5cf1-4e1a-81ba-0a1dcd111afa"},{"cell_type":"code","source":["import time\n","import numpy as np\n","\n","# Generate a large list of numbers\n","numbers = list(range(1000000))\n","\n","# Time regular Python loop\n","start = time.time()\n","doubled_list = [n * 2 for n in numbers]\n","end = time.time()\n","print(f\"⏳ Python list time: {end - start:.9f} seconds\")\n","\n","# Time NumPy operation\n","np_array = np.array(numbers)\n","start = time.time()\n","doubled_np = np_array * 2\n","end = time.time()\n","print(f\"⚡ NumPy time: {end - start:.9f} seconds\")\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f5a0121f-f32c-49b4-b28d-093ca0c0aa7f"},{"cell_type":"markdown","source":["### ✅ Why This Matters\n","###### List comprehensions are fast but loop-based.\n","###### \n","###### NumPy is vectorised, using compiled C under the hood — usually much faster for large arrays."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"23f3050e-47e4-4f17-a29b-96b5c9bfe8e4"},{"cell_type":"markdown","source":["# 🧪 Exercise Time!\n","\n","Now it’s your turn to practise! Download the NumPy Exercises from the github site if you haven't done so already.\n","\n","✅ Try filling in the missing parts in the code cells below  \n","✅ Don’t worry if you get stuck – ask questions, test things out  \n","✅ Use the comments and examples as guidance  \n","\n","Remember: **practice builds confidence** 💪\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"847f91d2-8218-4d98-9e35-dee40abb579c"},{"cell_type":"markdown","source":["# 🐼 Pandas: The Essential Library for Data Analysis\n","\n","###### **Pandas** is a powerful Python library for **high-performance data manipulation and analysis**.  \n","###### It simplifies working with **structured data**, making it an essential tool for data scientists and analysts.\n","### \n","<br><br><br>\n","### ✅ Key Features of Pandas\n","###### - 📊 **DataFrame Manipulation** – Intuitive handling of tabular data with powerful indexing.\n","###### - ⏳ **Time Series Analysis** – Advanced tools for working with time-stamped data.\n","###### - 🛠 **Data Cleaning & Preparation** – Easily handle missing values, transformations, and preprocessing.\n","###### - 📂 **File Format Compatibility** – Import/export data from CSV, Excel, SQL, and more.\n","###### - 🔗 **Merging & Joining** – Combine datasets efficiently using smart indexing.\n","<br><br><br>\n","### 🔥 Why Use Pandas?\n","###### - **Efficient**: Optimized for speed and memory usage.\n","###### - **Flexible**: Works with many file formats and integrates with NumPy & Matplotlib.\n","###### - **Easy to Learn**: Simple, yet powerful syntax.\n","###### \n","###### 🚀 Pandas **forms the backbone of modern data science**, providing an easy-to-use interface for **cleaning, transforming, and analyzing data**.\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"0719b2ab-5324-493c-9509-da8a008edbb0"},{"cell_type":"markdown","source":["### 🔹 Attribute\n","###### An attribute is a value or property of an object. You access it without parentheses. Think of it as stored information, eg df.columns, df.shape"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7db05b54-453a-4a0f-94e5-7bc1660d49ba"},{"cell_type":"markdown","source":["### 🔹 Method\n","###### A method is like a function, but it's tied to a specific object. You call it with parentheses, and it usually acts on or with that object, eg, df.head(), df.describe()"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1f88d1c0-9da9-4b34-9c76-97e9df0293ef"},{"cell_type":"markdown","source":["## 🧰 Exploring Your DataFrame in Python\n","###### When working with data, it's important to understand what your DataFrame contains. Here are some common and useful methods and attributes for exploring a pandas DataFrame:\n","###### \n","###### .head() – Shows the first few rows (default is 5)\n","###### \n","###### .tail() – Shows the last few rows\n","###### \n","###### .columns – Lists all column names (an attribute, not a method)\n","###### \n","###### .dtypes – Shows the data type of each column\n","###### \n","###### .describe() – Gives summary statistics for numeric columns\n","###### \n","###### .isnull().sum() – Counts missing values in each column\n","###### \n","###### These are foundational tools for any data analyst or beginner working with pandas."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"555a735b-3784-4cb1-b570-2de67434597c"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Create a DataFrame from a dictionary\n","data = {\n","    'Temperature (C)': [20, 22, 24, 26, 28],\n","    'Humidity (%)': [30, 35, 40, 45, 50]\n","}\n","\n","#This creates a DataFrame with two columns, each column is essentially a NumPy array under the hood\n","dfWeather = pd.DataFrame(data)\n","print(dfWeather)\n","type(dfWeather)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"56d0eb0e-cf94-44d2-b2ff-0705d8453ae2"},{"cell_type":"code","source":["print(f\"First five rows of the data:\\n{dfWeather.head()}\\n\")\n","print(f\"Last five rows of the data:\\n{dfWeather.tail()}\\n\")\n","print(f\"Column names:\\n{dfWeather.columns}\\n\")\n","print(f\"Data types of each column:\\n{dfWeather.dtypes}\\n\")\n","print(f\"Summary statistics:\\n{dfWeather.describe()}\\n\")\n","print(f\"Number of missing values per column:\\n{dfWeather.isnull().sum()}\\n\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7f691ccd-c9e9-40af-9ae6-fc77e660fb34"},{"cell_type":"code","source":["# Create a date range\n","dates = pd.date_range(start=\"2025-03-01\", periods=5, freq=\"D\")\n","\n","\n","# Set the date index\n","dfWeather.index = dates\n","print(dfWeather)\n","\n","print(dfWeather.index)\n","print(type(dfWeather.index))\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b4cda353-958d-4107-bb62-43277a61199b"},{"cell_type":"markdown","source":["### 📅 Date as Index – What and Why?\n","\n","When you set a date column as the index in a DataFrame, Pandas converts it to a **`DatetimeIndex`**.\n","\n","#### ✅ What is a `DatetimeIndex`?\n","- It’s a special type of index in Pandas designed for time-based data.\n","- It allows smart slicing, filtering, and resampling using dates.\n","\n","#### 🔍 Why it’s useful:\n","- You can easily select rows by date:\n","  ```python\n","  df.loc['2025-03-03']\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"71bbbed3-b86e-449d-894e-6fc3322318ab"},{"cell_type":"code","source":["print(dfWeather.loc['2025-03'])\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"efc1287d-75a7-465c-bdd4-d59ad9b54ee2"},{"cell_type":"markdown","source":["###### You can resample data by month, week, day, etc.:"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0e600f93-742b-4fce-930b-ad4217e80956"},{"cell_type":"code","source":["dfWeather.resample('M').mean()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3fd0b62a-3e2e-4aa3-bb18-e9ec511ea712"},{"cell_type":"markdown","source":["https://app.datacamp.com/learn/tutorials/loc-vs-iloc\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"run_control":{"frozen":false},"editable":true},"id":"dc437945-6318-45b1-814b-2545f9d0b7db"},{"cell_type":"markdown","source":["##### 🔍 Using .iloc (integer position)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"53a56211-b7a8-4b1e-b12c-ef49ed0982bf"},{"cell_type":"code","source":["# Row at index 2\n","print(dfWeather)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2170122d-4f3e-43e7-b0a0-368f486b0abb"},{"cell_type":"code","source":["print(dfWeather.iloc[2])\n","# Output:\n","# Temperature (C)    24\n","# Humidity (%)       40"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e9ebf4d8-496f-4c6c-b162-eded76fc9649"},{"cell_type":"code","source":["# Element at row 1, column 0\n","print(dfWeather.iloc[1, 0])  # Output: 22"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6476be96-029d-46c2-a2cd-868a22815f26"},{"cell_type":"code","source":["# First 3 rows, both columns\n","print(dfWeather.iloc[:3, :])"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"70b31746-4038-48d6-84a0-45f7fd6bfdbf"},{"cell_type":"markdown","source":["##### 🔍 Using .loc (label index)\n","###### \n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cc1ea9d6-5a6e-443d-a1d7-3533742f6907"},{"cell_type":"code","source":["print(dfWeather)\n","\n","# Row with date '2025-03-03' \n","print(dfWeather.loc['2025-03-03'])\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"31aceff7-3a81-4e81-80ca-35c801ffb44b"},{"cell_type":"code","source":["# Element at date '2025-03-04', column 'Humidity (%)'\n","print(dfWeather.loc['2025-03-04', 'Humidity (%)'])"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b7cc87f2-dbb7-4e31-8abe-ffd6254c8e2e"},{"cell_type":"code","source":["# Rows from '2025-03-02' to '2025-03-04', specific columns.  NB: because it is a specific value at the end, that value is included \n","print(dfWeather.loc['2025-03-02':'2025-03-04', ['Temperature (C)', 'Humidity (%)']])\n","\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"819a0f92-7759-4696-81ce-6fb87f4f795f"},{"cell_type":"code","source":["# Add a new column for temperature in Fahrenheit\n","# note the syntax to select a column\n","dfWeather['Temperature (F)'] = dfWeather['Temperature (C)'] * 9/5 + 32\n","print(dfWeather)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6b65ea0c-82ba-43f9-b1ce-3ef2dbf8e0bf"},{"cell_type":"code","source":["# Filter rows where Humidity is greater than 40%\n","# Note the syntax - first set of brackets sepcifies the context, eg, filtering, \n","# second set applies the boolean mask to the dataframe and selects only those rows\n","\n","high_humidity = dfWeather[dfWeather['Humidity (%)'] > 40]\n","print(high_humidity)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3138faf9-6b57-4e07-ab51-f121712bc9a4"},{"cell_type":"markdown","source":["## Let's put it all together with data - you will need the HR_file.csv"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f8095a1c-c853-417b-ad80-efaec2ce85ee"},{"cell_type":"markdown","source":["# 🧪 Exercise Time!\n","\n","Now it’s your turn to practise! We are going to upload the HR_File.csv from the git hub site\n","\n","✅ Try filling in the missing parts in the code cells below  \n","✅ Don’t worry if you get stuck – ask questions, test things out  \n","✅ Use the comments and examples as guidance  \n","\n","Remember: **practice builds confidence** 💪\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e4a70c58-6161-48ab-bbb4-c75cdb8a54ef"},{"cell_type":"code","source":["# Example: Sequential steps\n","print(\"Step 1: Importing data\")\n","\n","import pandas as pd\n","import numpy as np\n","\n","# Load data into pandas DataFrame from \"/lakehouse/default/\" + \"Files/HR_file.csv\"\n","df = pd.read_csv(\"/lakehouse/default/\" + \"Files/HR_file.csv\", delimiter=',')\n","\n","print(\"Step 2: Data loaded successfully.  \\nHere's the dataframe\")\n","display(df)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"efb37c7d-2197-493d-89ed-48433800ccac"},{"cell_type":"markdown","source":["Add in summary from exercise to next section"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"88bce6ec-a0d3-4657-9578-3d3fa61ab3c5"},{"cell_type":"markdown","source":["## 📥 Input and Output Readers in Pandas\n","\n","###### Pandas allows for easy **data export** to various formats, including **CSV**, **Excel**, and **SQL**.  \n","###### When working with **Microsoft Fabric Lakehouse**, you need to use the correct file path format.\n","###### \n","### ✅ Example: Saving a DataFrame to a CSV in the Default Lakehouse\n","\n","###### 📌 **Key Notes:**\n","###### - The **default Lakehouse path** is `/lakehouse/default/`.\n","###### - The **filename and folder structure** must be specified correctly.\n","###### - Setting `index=False` ensures that the DataFrame index is **not saved** in the CSV.\n","\n","### 📂 Other File Formats Supported by Pandas\n","| **Format**  | **Save Method** | **Read Method** |\n","|------------|----------------|----------------|\n","| CSV        | `df.to_csv('file.csv')` | `pd.read_csv('file.csv')` |\n","| Excel      | `df.to_excel('file.xlsx')` | `pd.read_excel('file.xlsx')` |\n","| JSON       | `df.to_json('file.json')` | `pd.read_json('file.json')` |\n","| Parquet    | `df.to_parquet('file.parquet')` | `pd.read_parquet('file.parquet')` |\n","| SQL        | `df.to_sql('table', conn)` | `pd.read_sql('SELECT * FROM table', conn)` |\n","\n","###### 🚀 **Pandas makes input and output operations seamless across multiple formats!**\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5e4b9dcd-a382-4a68-b03f-e9f4f960980d"},{"cell_type":"markdown","source":["## 🔹 Saving Data to CSV"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e4c5bd5d-a904-48fe-824d-01405dde3664"},{"cell_type":"code","source":["# Save to csv\n","dfWeather.to_csv('/lakehouse/default/' + 'Files/dfWeatherVancouver.csv', index=False)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c910e680-3d31-4da8-9def-7a47ce3aff06"},{"cell_type":"markdown","source":["## 🔹 Importing Data from CSV"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ec88c2ac-dd8d-4298-a185-001ea8b80337"},{"cell_type":"code","source":["import pandas as pd\n","\n","# Define base path as a variable\n","base_path = \"/lakehouse/default/Files\"\n","\n","# Combine with filename\n","file_name = \"HR_file.csv\"\n","file_path = f\"{base_path}/{file_name}\"\n","\n","# Load data\n","df = pd.read_csv(file_path, delimiter=',')\n","\n","# Display\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"aa3b4a25-5e73-4d4b-890e-af97ea122eae"}],"metadata":{"language_info":{"name":"python"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"},"language_group":"synapse_pyspark"},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"300bf873-d380-4f73-8685-642a0f911bbd","known_lakehouses":[{"id":"300bf873-d380-4f73-8685-642a0f911bbd"}],"default_lakehouse_name":"PythonIntro","default_lakehouse_workspace_id":"0ab57829-4ee1-4a0a-8678-6b07f7109f8f"}}},"nbformat":4,"nbformat_minor":5}