{"cells":[{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"41ce1cbc-712f-4be0-bf5c-7df8dce7ad32"},{"cell_type":"markdown","source":["## ğŸ§  Let's Check In!\n","\n","## Go to ğŸ‘‰ [www.menti.com](https://www.menti.com)  \n","## and enter the code: **6247 1541**\n","## \n","## > ğŸ’¬ Answer the question on screen â€” your response will appear live!"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b6a6fa85-9671-4ca1-baec-44be6e563079"},{"cell_type":"code","source":["import pandas as pd\n","# Load data into pandas DataFrame from \"/lakehouse/default/Files/HR_file.csv\"\n","df = pd.read_csv(\"/lakehouse/default/Files/HR_file.csv\")\n","display(df)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"b9056c4e-b2df-46e6-a02e-118a02a5d67a"},{"cell_type":"markdown","source":["## ğŸ”¢ NumPy: The Powerhouse of Numerical Computing\n","\n","###### NumPy is a powerful library for **efficient numerical computing in Python**.  \n","###### It provides **fast mathematical operations**, **multi-dimensional arrays**, and **integration with other data tools**.\n","###### \n","###### âœ… Why Use NumPy?\n","###### - ğŸš€ **Efficient Array Handling** â€“ Much faster than Python lists\n","###### - ğŸ“ **Multi-dimensional Array Support** â€“ Supports matrices, tensors, and more\n","###### - ğŸ”¢ **Slicing & Indexing** â€“ Similar to lists but more powerful\n","###### - ğŸ¤ **Integrates with**:\n","- ###### **Pandas** â€“ Forms the backbone of DataFrames & Series\n","- ###### **Matplotlib** â€“ Used for visualization in Python\n","- ###### **Scikit-learn** â€“ Essential for Machine Learning\n","###### \n","###### â³ Performance Comparison\n","###### - âœ… **Python List Time:** Much slower than NumPy  \n","###### - ğŸš€ **NumPy Array Time:** Optimized for fast calculations  \n","###### "],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5030684b-cd86-46b0-8c88-f2267d170d5f"},{"cell_type":"markdown","source":["##### ğŸ”¢ 1. Multi-Dimensional Arrays in NumPy\n","###### â¡ï¸ NumPy makes it easy to work with 2D and 3D arrays â€” just like Excel sheets or image data."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d92fe41b-5f4b-4930-aaeb-b8663089aaf1"},{"cell_type":"code","source":["import numpy as np\n","\n","# Create a 2D array (like a matrix)\n","matrix = np.array([[1, 2, 3],\n","                   [4, 5, 6],\n","                   [7, 8, 9]])\n","\n","print(\"ğŸ“ 2D Array:\\n\", matrix)\n","\n","# Access the first row\n","print(\"First row:\", matrix[0])\n","\n","# Access the item at row 2, column 3 (index [1, 2])\n","print(\"Item at (2, 3):\", matrix[1, 2])\n","\n","# Slice a sub-matrix (rows 1â€“2, columns 1â€“2) nb the end is exclusive, but the start is inclusive!!\n","print(\"Sub-matrix:\\n\", matrix[0:2, 0:2])\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6f7b6d6a-ee75-43ad-852c-43862f3fc865"},{"cell_type":"markdown","source":["##### ğŸ“Š 2. Simple Broadcasting (Scalar + Array)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"716fb528-4ac3-4b4e-a654-ee3e7a9c7ab1"},{"cell_type":"code","source":["print(\"ğŸ“ matrix:\\n\", matrix)\n","\n","# Add 10 to every element (scalar broadcasting)\n","print(\"Add 10:\\n\", matrix + 10)\n","\n","# Multiply all values by 2\n","print(\"Double values:\\n\", matrix * 2)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ae6b3eae-1f37-4a15-b6c5-cfe68498de3e"},{"cell_type":"markdown","source":["##### ğŸ”„ 3. Row-wise Broadcasting"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"30409917-77e6-4bab-a677-412b9dc7d798"},{"cell_type":"code","source":["print(\"ğŸ“ matrix:\\n\", matrix)\n","# Add a 1D array to each row (broadcasts across rows)\n","\n","\n","row_add = np.array([1, 10, -1]) # for each row do this to each column\n","print(\"Row-wise add:\\n\", matrix + row_add)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fee973d5-4794-45e1-a6b8-04f1eee82e25"},{"cell_type":"markdown","source":["##### ğŸ” 4. Column-Wise Broadcasting and `.reshape()`\n","\n","If you want to add values **down the columns** of a 2D matrix (i.e., column-wise),\n","you need a column vector. You can create this by reshaping a 1D array.\n","\n","This ensures the shape lines up for broadcasting:\n","- âœ… Shape of matrix: `(rows, columns)`\n","- âœ… Shape of column vector: `(rows, 1)` â€“ one value per row\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0f8151d4-a019-4964-9dbc-ff00a3524aaf"},{"cell_type":"code","source":["print(\"ğŸ“ Matrix:\\n\", matrix)\n","\n","# Create a column vector with one value per row\n","col_add = np.array([10, 20, 30]).reshape(3, 1)\n","\n","print(col_add) # similar to transpose in excel\n","\n","# Broadcast column vector across each row\n","print(\"Column-wise add:\\n\", matrix + col_add)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b972bcc9-8805-4a47-8e69-e89d1d5f3861"},{"cell_type":"markdown","source":["##### ğŸ“ˆ 5. Visualise a NumPy Array with Matplotlib\n","###### â¡ï¸ Turn your array into a quick line chart"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4abaf490-d5a9-406b-84bb-82c24e028243"},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Create a simple NumPy array\n","data = np.array([2, 4, 6, 8, 10, 12])\n","\n","# Plot the array\n","plt.plot(data)\n","plt.title(\"ğŸ“Š Simple Line Plot from NumPy\")\n","plt.xlabel(\"Title\")\n","plt.ylabel(\"Value\")\n","#plt.grid(True)\n","#plt.show()\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0e437272-5cf1-4e1a-81ba-0a1dcd111afa"},{"cell_type":"code","source":["import time\n","import numpy as np\n","\n","# Generate a large list of numbers\n","numbers = list(range(1000000))\n","\n","# Time regular Python loop\n","start = time.time()\n","doubled_list = [n * 2 for n in numbers]\n","end = time.time()\n","print(f\"â³ Python list time: {end - start:.9f} seconds\")\n","\n","# Time NumPy operation\n","np_array = np.array(numbers)\n","start = time.time()\n","doubled_np = np_array * 2\n","end = time.time()\n","print(f\"âš¡ NumPy time: {end - start:.9f} seconds\")\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f5a0121f-f32c-49b4-b28d-093ca0c0aa7f"},{"cell_type":"markdown","source":["### âœ… Why This Matters\n","###### List comprehensions are fast but loop-based.\n","###### \n","###### NumPy is vectorised, using compiled C under the hood â€” usually much faster for large arrays."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"23f3050e-47e4-4f17-a29b-96b5c9bfe8e4"},{"cell_type":"markdown","source":["# ğŸ§ª Exercise Time!\n","\n","Now itâ€™s your turn to practise! Download the NumPy Exercises from the github site if you haven't done so already.\n","\n","âœ… Try filling in the missing parts in the code cells below  \n","âœ… Donâ€™t worry if you get stuck â€“ ask questions, test things out  \n","âœ… Use the comments and examples as guidance  \n","\n","Remember: **practice builds confidence** ğŸ’ª\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"847f91d2-8218-4d98-9e35-dee40abb579c"},{"cell_type":"markdown","source":["# ğŸ¼ Pandas: The Essential Library for Data Analysis\n","\n","###### **Pandas** is a powerful Python library for **high-performance data manipulation and analysis**.  \n","###### It simplifies working with **structured data**, making it an essential tool for data scientists and analysts.\n","### \n","<br><br><br>\n","### âœ… Key Features of Pandas\n","###### - ğŸ“Š **DataFrame Manipulation** â€“ Intuitive handling of tabular data with powerful indexing.\n","###### - â³ **Time Series Analysis** â€“ Advanced tools for working with time-stamped data.\n","###### - ğŸ›  **Data Cleaning & Preparation** â€“ Easily handle missing values, transformations, and preprocessing.\n","###### - ğŸ“‚ **File Format Compatibility** â€“ Import/export data from CSV, Excel, SQL, and more.\n","###### - ğŸ”— **Merging & Joining** â€“ Combine datasets efficiently using smart indexing.\n","<br><br><br>\n","### ğŸ”¥ Why Use Pandas?\n","###### - **Efficient**: Optimized for speed and memory usage.\n","###### - **Flexible**: Works with many file formats and integrates with NumPy & Matplotlib.\n","###### - **Easy to Learn**: Simple, yet powerful syntax.\n","###### \n","###### ğŸš€ Pandas **forms the backbone of modern data science**, providing an easy-to-use interface for **cleaning, transforming, and analyzing data**.\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"0719b2ab-5324-493c-9509-da8a008edbb0"},{"cell_type":"markdown","source":["### ğŸ”¹ Attribute\n","###### An attribute is a value or property of an object. You access it without parentheses. Think of it as stored information, eg df.columns, df.shape"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7db05b54-453a-4a0f-94e5-7bc1660d49ba"},{"cell_type":"markdown","source":["### ğŸ”¹ Method\n","###### A method is like a function, but it's tied to a specific object. You call it with parentheses, and it usually acts on or with that object, eg, df.head(), df.describe()"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1f88d1c0-9da9-4b34-9c76-97e9df0293ef"},{"cell_type":"markdown","source":["## ğŸ§° Exploring Your DataFrame in Python\n","###### When working with data, it's important to understand what your DataFrame contains. Here are some common and useful methods and attributes for exploring a pandas DataFrame:\n","###### \n","###### .head() â€“ Shows the first few rows (default is 5)\n","###### \n","###### .tail() â€“ Shows the last few rows\n","###### \n","###### .columns â€“ Lists all column names (an attribute, not a method)\n","###### \n","###### .dtypes â€“ Shows the data type of each column\n","###### \n","###### .describe() â€“ Gives summary statistics for numeric columns\n","###### \n","###### .isnull().sum() â€“ Counts missing values in each column\n","###### \n","###### These are foundational tools for any data analyst or beginner working with pandas."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"555a735b-3784-4cb1-b570-2de67434597c"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Create a DataFrame from a dictionary\n","data = {\n","    'Temperature (C)': [20, 22, 24, 26, 28],\n","    'Humidity (%)': [30, 35, 40, 45, 50]\n","}\n","\n","#This creates a DataFrame with two columns, each column is essentially a NumPy array under the hood\n","dfWeather = pd.DataFrame(data)\n","print(dfWeather)\n","type(dfWeather)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"56d0eb0e-cf94-44d2-b2ff-0705d8453ae2"},{"cell_type":"code","source":["print(f\"First five rows of the data:\\n{dfWeather.head()}\\n\")\n","print(f\"Last five rows of the data:\\n{dfWeather.tail()}\\n\")\n","print(f\"Column names:\\n{dfWeather.columns}\\n\")\n","print(f\"Data types of each column:\\n{dfWeather.dtypes}\\n\")\n","print(f\"Summary statistics:\\n{dfWeather.describe()}\\n\")\n","print(f\"Number of missing values per column:\\n{dfWeather.isnull().sum()}\\n\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7f691ccd-c9e9-40af-9ae6-fc77e660fb34"},{"cell_type":"code","source":["# Create a date range\n","dates = pd.date_range(start=\"2025-03-01\", periods=5, freq=\"D\")\n","\n","\n","# Set the date index\n","dfWeather.index = dates\n","print(dfWeather)\n","\n","print(dfWeather.index)\n","print(type(dfWeather.index))\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b4cda353-958d-4107-bb62-43277a61199b"},{"cell_type":"markdown","source":["### ğŸ“… Date as Index â€“ What and Why?\n","\n","When you set a date column as the index in a DataFrame, Pandas converts it to a **`DatetimeIndex`**.\n","\n","#### âœ… What is a `DatetimeIndex`?\n","- Itâ€™s a special type of index in Pandas designed for time-based data.\n","- It allows smart slicing, filtering, and resampling using dates.\n","\n","#### ğŸ” Why itâ€™s useful:\n","- You can easily select rows by date:\n","  ```python\n","  df.loc['2025-03-03']\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"71bbbed3-b86e-449d-894e-6fc3322318ab"},{"cell_type":"code","source":["print(dfWeather.loc['2025-03'])\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"efc1287d-75a7-465c-bdd4-d59ad9b54ee2"},{"cell_type":"markdown","source":["###### You can resample data by month, week, day, etc.:"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0e600f93-742b-4fce-930b-ad4217e80956"},{"cell_type":"code","source":["dfWeather.resample('M').mean()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3fd0b62a-3e2e-4aa3-bb18-e9ec511ea712"},{"cell_type":"markdown","source":["https://app.datacamp.com/learn/tutorials/loc-vs-iloc\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"run_control":{"frozen":false},"editable":true},"id":"dc437945-6318-45b1-814b-2545f9d0b7db"},{"cell_type":"markdown","source":["##### ğŸ” Using .iloc (integer position)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"53a56211-b7a8-4b1e-b12c-ef49ed0982bf"},{"cell_type":"code","source":["# Row at index 2\n","print(dfWeather)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2170122d-4f3e-43e7-b0a0-368f486b0abb"},{"cell_type":"code","source":["print(dfWeather.iloc[2])\n","# Output:\n","# Temperature (C)    24\n","# Humidity (%)       40"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e9ebf4d8-496f-4c6c-b162-eded76fc9649"},{"cell_type":"code","source":["# Element at row 1, column 0\n","print(dfWeather.iloc[1, 0])  # Output: 22"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6476be96-029d-46c2-a2cd-868a22815f26"},{"cell_type":"code","source":["# First 3 rows, both columns\n","print(dfWeather.iloc[:3, :])"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"70b31746-4038-48d6-84a0-45f7fd6bfdbf"},{"cell_type":"markdown","source":["##### ğŸ” Using .loc (label index)\n","###### \n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cc1ea9d6-5a6e-443d-a1d7-3533742f6907"},{"cell_type":"code","source":["print(dfWeather)\n","\n","# Row with date '2025-03-03' \n","print(dfWeather.loc['2025-03-03'])\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"31aceff7-3a81-4e81-80ca-35c801ffb44b"},{"cell_type":"code","source":["# Element at date '2025-03-04', column 'Humidity (%)'\n","print(dfWeather.loc['2025-03-04', 'Humidity (%)'])"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b7cc87f2-dbb7-4e31-8abe-ffd6254c8e2e"},{"cell_type":"code","source":["# Rows from '2025-03-02' to '2025-03-04', specific columns.  NB: because it is a specific value at the end, that value is included \n","print(dfWeather.loc['2025-03-02':'2025-03-04', ['Temperature (C)', 'Humidity (%)']])\n","\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"819a0f92-7759-4696-81ce-6fb87f4f795f"},{"cell_type":"code","source":["# Add a new column for temperature in Fahrenheit\n","# note the syntax to select a column\n","dfWeather['Temperature (F)'] = dfWeather['Temperature (C)'] * 9/5 + 32\n","print(dfWeather)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6b65ea0c-82ba-43f9-b1ce-3ef2dbf8e0bf"},{"cell_type":"code","source":["# Filter rows where Humidity is greater than 40%\n","# Note the syntax - first set of brackets sepcifies the context, eg, filtering, \n","# second set applies the boolean mask to the dataframe and selects only those rows\n","\n","high_humidity = dfWeather[dfWeather['Humidity (%)'] > 40]\n","print(high_humidity)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3138faf9-6b57-4e07-ab51-f121712bc9a4"},{"cell_type":"markdown","source":["## Let's put it all together with data - you will need the HR_file.csv"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f8095a1c-c853-417b-ad80-efaec2ce85ee"},{"cell_type":"markdown","source":["# ğŸ§ª Exercise Time!\n","\n","Now itâ€™s your turn to practise! We are going to upload the HR_File.csv from the git hub site\n","\n","âœ… Try filling in the missing parts in the code cells below  \n","âœ… Donâ€™t worry if you get stuck â€“ ask questions, test things out  \n","âœ… Use the comments and examples as guidance  \n","\n","Remember: **practice builds confidence** ğŸ’ª\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e4a70c58-6161-48ab-bbb4-c75cdb8a54ef"},{"cell_type":"code","source":["# Example: Sequential steps\n","print(\"Step 1: Importing data\")\n","\n","import pandas as pd\n","import numpy as np\n","\n","# Load data into pandas DataFrame from \"/lakehouse/default/\" + \"Files/HR_file.csv\"\n","df = pd.read_csv(\"/lakehouse/default/\" + \"Files/HR_file.csv\", delimiter=',')\n","\n","print(\"Step 2: Data loaded successfully.  \\nHere's the dataframe\")\n","display(df)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"efb37c7d-2197-493d-89ed-48433800ccac"},{"cell_type":"markdown","source":["Add in summary from exercise to next section"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"88bce6ec-a0d3-4657-9578-3d3fa61ab3c5"},{"cell_type":"markdown","source":["## ğŸ“¥ Input and Output Readers in Pandas\n","\n","###### Pandas allows for easy **data export** to various formats, including **CSV**, **Excel**, and **SQL**.  \n","###### When working with **Microsoft Fabric Lakehouse**, you need to use the correct file path format.\n","###### \n","### âœ… Example: Saving a DataFrame to a CSV in the Default Lakehouse\n","\n","###### ğŸ“Œ **Key Notes:**\n","###### - The **default Lakehouse path** is `/lakehouse/default/`.\n","###### - The **filename and folder structure** must be specified correctly.\n","###### - Setting `index=False` ensures that the DataFrame index is **not saved** in the CSV.\n","\n","### ğŸ“‚ Other File Formats Supported by Pandas\n","| **Format**  | **Save Method** | **Read Method** |\n","|------------|----------------|----------------|\n","| CSV        | `df.to_csv('file.csv')` | `pd.read_csv('file.csv')` |\n","| Excel      | `df.to_excel('file.xlsx')` | `pd.read_excel('file.xlsx')` |\n","| JSON       | `df.to_json('file.json')` | `pd.read_json('file.json')` |\n","| Parquet    | `df.to_parquet('file.parquet')` | `pd.read_parquet('file.parquet')` |\n","| SQL        | `df.to_sql('table', conn)` | `pd.read_sql('SELECT * FROM table', conn)` |\n","\n","###### ğŸš€ **Pandas makes input and output operations seamless across multiple formats!**\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5e4b9dcd-a382-4a68-b03f-e9f4f960980d"},{"cell_type":"markdown","source":["## ğŸ”¹ Saving Data to CSV"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e4c5bd5d-a904-48fe-824d-01405dde3664"},{"cell_type":"code","source":["# Save to csv\n","dfWeather.to_csv('/lakehouse/default/' + 'Files/dfWeatherVancouver.csv', index=False)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c910e680-3d31-4da8-9def-7a47ce3aff06"},{"cell_type":"markdown","source":["## ğŸ”¹ Importing Data from CSV"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ec88c2ac-dd8d-4298-a185-001ea8b80337"},{"cell_type":"code","source":["import pandas as pd\n","\n","# Define base path as a variable\n","base_path = \"/lakehouse/default/Files\"\n","\n","# Combine with filename\n","file_name = \"HR_file.csv\"\n","file_path = f\"{base_path}/{file_name}\"\n","\n","# Load data\n","df = pd.read_csv(file_path, delimiter=',')\n","\n","# Display\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"aa3b4a25-5e73-4d4b-890e-af97ea122eae"}],"metadata":{"language_info":{"name":"python"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"},"language_group":"synapse_pyspark"},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"300bf873-d380-4f73-8685-642a0f911bbd","known_lakehouses":[{"id":"300bf873-d380-4f73-8685-642a0f911bbd"}],"default_lakehouse_name":"PythonIntro","default_lakehouse_workspace_id":"0ab57829-4ee1-4a0a-8678-6b07f7109f8f"}}},"nbformat":4,"nbformat_minor":5}