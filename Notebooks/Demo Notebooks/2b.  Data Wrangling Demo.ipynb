{"cells":[{"cell_type":"markdown","source":["## ğŸ§° Data Wrangling with pandas â€“ Demo\n","\n","###### In this notebook, weâ€™ll walk through examples of how to:\n","###### - Transform columns\n","###### - Join DataFrames\n","###### - Merge DataFrames\n","###### - Append rows"],"metadata":{},"id":"ee15d5ef"},{"cell_type":"markdown","source":["### ğŸ§° Core Data Wrangling Functions in pandas\n","\n","Pandas gives us powerful tools to reshape and clean data. Here are some of the most commonly used wrangling functions:\n","\n","##### ğŸ” Transforming Data\n","###### - `df['col'].apply(func)` â€“ Apply a function to each value\n","###### - `df['new_col'] = df['col1'] + df['col2']` â€“ Create new columns\n","###### - `pd.cut()` â€“ Bin numeric data into categories\n","\n","##### ğŸ”— Joining and Merging\n","- `df1.join(df2)` â€“ Join two DataFrames by index\n","- `pd.merge(df1, df2, on='key')` â€“ Merge on one or more columns\n","\n","##### â• Appending and Concatenating\n","- `pd.concat([df1, df2])` â€“ Stack DataFrames vertically or side-by-side\n","- `df.append(new_row)` â€“ Add a single new row (deprecated in future, use `pd.concat`)\n","\n","##### ğŸ§¼ Cleaning and Filtering\n","- `df.dropna()` â€“ Remove rows with missing values\n","- `df.drop_duplicates()` â€“ Remove duplicate rows\n","- `df[df['col'] == 'value']` â€“ Filter rows based on a condition\n","\n","##### ğŸ“Š Grouping and Aggregating\n","- `df.groupby('col').mean()` â€“ Group by one column and calculate average\n","- `df.agg({'col1': 'sum', 'col2': 'mean'})` â€“ Apply different functions to columns\n","\n","ğŸ“Œ These building blocks help you clean, combine, and prepare data for analysis or visualisation.\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"223fa4e5-fcbb-4bc1-9985-d876b1dac77b"},{"cell_type":"markdown","source":["#### ğŸ“¦ Step 1: Create Sample Datasets"],"metadata":{},"id":"e78ca5c1"},{"cell_type":"code","source":["import pandas as pd\n","\n","# Dataset 1 â€“ Employees\n","df_employees = pd.DataFrame({\n","    'EmployeeID': [1, 2, 3],\n","    'FirstName': ['Alice', 'SpongeBob', 'Charlie'],\n","    'LastName': ['InWonderland', 'SquarePants', 'Brown'],\n","    'Department': ['HR', 'IT', 'Finance']\n","})\n","\n","# Dataset 2 â€“ Salaries\n","df_salaries = pd.DataFrame({\n","    'EmployeeID': [1, 2, 4],\n","    'Salary': [60001, 30000, 55000]\n","})\n","\n","df_employees, df_salaries"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a2eee83f"},{"cell_type":"markdown","source":["#### âœ‚ï¸ Step 2: Transform Columns"],"metadata":{},"id":"e28bfecd"},{"cell_type":"code","source":["# Add a new column with salary band using conditions\n","df_salaries['SalaryBand'] = pd.cut(df_salaries['Salary'], bins=[0, 35000, 60000, 100000],\n","                                   labels=['Low', 'Medium', 'High'])\n","df_salaries"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c285cde4"},{"cell_type":"markdown","source":["#### ğŸ”— Step 3: Join DataFrames using `.join()`\n","\n","\n","##### <img src=\"https://i.ibb.co/KzmBDh5f/SQL-Joins.jpg\" alt=\"LinkedIn QR Code\" width=\"900\"/>\n"],"metadata":{},"id":"2b27a5cc"},{"cell_type":"code","source":["# Set EmployeeID as index for join\n","df_employees_join = df_employees.set_index('EmployeeID')\n","df_salaries_join = df_salaries.set_index('EmployeeID')\n","\n","# Join salaries to employees\n","joined_df = df_employees_join.join(df_salaries_join, how='left')\n","joined_df"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"781c39a1"},{"cell_type":"markdown","source":["##### What happens if you want to use a composite key?"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8bf1f65e-3e9a-4db7-b10b-c4eabaa9eebc"},{"cell_type":"markdown","source":["##### ğŸ”— Joining DataFrames on Composite Keys\n","###### Sometimes, a single column isnâ€™t enough to uniquely identify a match between two datasets. In those cases, we use a composite key â€” a combination of two or more columns â€” to perform the join.\n","\n","##### âœ… Step-by-step:\n","###### 1. Set a composite index on both DataFrames\n","###### Weâ€™ll use FirstName and LastName as the join keys for teaching purposes only:"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f86fe1e3-ad48-46de-a4c0-2b3ea6e264e4"},{"cell_type":"code","source":["# ğŸ‘©â€ğŸ’¼ Employees DataFrame\n","df_employees = pd.DataFrame({\n","    'FirstName': ['Alice', 'Bob', 'Charlie', 'Diana'],\n","    'LastName': ['Smith', 'Jones', 'Brown', 'Lee'],\n","    'Department': ['HR', 'Finance', 'IT', 'Marketing']\n","})\n","\n","# ğŸ’° Salaries DataFrame\n","df_salaries = pd.DataFrame({\n","    'FirstName': ['Alice', 'Bob', 'Charlie'],\n","    'LastName': ['Smith', 'Jones', 'Brown'],\n","    'Salary': [50000, 60000, 55000]\n","})\n","\n","# ğŸ”— Set composite index on both\n","df_employees_join = df_employees.set_index(['FirstName', 'LastName'])\n","df_salaries_join = df_salaries.set_index(['FirstName', 'LastName'])\n","\n","# ğŸ”„ Join on composite key\n","joined_df = df_employees_join.join(df_salaries_join, how='left')\n","\n","# ğŸ‘€ View result\n","print(joined_df.reset_index())"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"607cf4f5-5c5c-40dd-907a-cf6cc44e8509"},{"cell_type":"markdown","source":["#### ğŸ”€ Step 4: Merge DataFrames using `.merge()`"],"metadata":{},"id":"d0e52456"},{"cell_type":"code","source":["# Merge based on EmployeeID column\n","merged_df = pd.merge(df_employees, df_salaries, on='EmployeeID', how='outer')\n","merged_df"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a2cccd9f"},{"cell_type":"markdown","source":["#### â• Step 5: Append Rows"],"metadata":{},"id":"a798337d"},{"cell_type":"code","source":["# Create a new employee to append\n","new_row = pd.DataFrame([{'EmployeeID': 5, 'Name': 'Diana', 'Department': 'Marketing'}])\n","df_employees_appended = pd.concat([df_employees, new_row], ignore_index=True)\n","df_employees_appended"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a3ff8118"}],"metadata":{"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"kernel_info":{"name":"synapse_pyspark"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"300bf873-d380-4f73-8685-642a0f911bbd"}],"default_lakehouse":"300bf873-d380-4f73-8685-642a0f911bbd","default_lakehouse_name":"PythonIntro","default_lakehouse_workspace_id":"0ab57829-4ee1-4a0a-8678-6b07f7109f8f"}}},"nbformat":4,"nbformat_minor":5}