{"cells":[{"cell_type":"code","source":["# Welcome to your new notebook\n","# Type here in the cell editor to add code!\n","%pip install semantic-link-labs"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a3fb06ad-682f-4f8d-9c81-0d5bfc16c088"},{"cell_type":"code","source":["import sempy_labs as labs\n","import sempy_labs.report as rep\n","import sempy.fabric as fabric\n","from sempy_labs import admin\n","from datetime import datetime, timedelta\n","import pandas as pd\n","\n","admin.list_tenant_settings()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0d753ad7-741d-44a2-b20f-22d8751a5722"},{"cell_type":"code","source":["# Test to make sure that activity events are working\n","\n","today = datetime.utcnow().strftime(\"%Y-%m-%d\")\n","start_time = f\"{today}T00:00:00\"\n","end_time = f\"{today}T23:59:59\"\n","\n","\n","df = admin.list_activity_events(start_time=start_time, end_time=end_time, activity_filter=None)\n","display(df)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"5b7872a2-ec22-41c1-bb62-d11cf96abc73"},{"cell_type":"code","source":["# Loop through last 30 days\n","\n","# üîß Config\n","days_back = 30  # how many days of history to pull\n","activity_filter = \"viewreport\"\n","all_logs = []\n","\n","# üïí Loop through one day at a time\n","for i in range(days_back):\n","    day = datetime.utcnow() - timedelta(days=i)\n","    start_time = f\"{day.strftime('%Y-%m-%d')}T00:00:00\"\n","    end_time = f\"{day.strftime('%Y-%m-%d')}T23:59:59\"\n","\n","    try:\n","        df_day = admin.list_activity_events(\n","            start_time=start_time,\n","            end_time=end_time,\n","            activity_filter=activity_filter\n","        )\n","        if not df_day.empty:\n","            print(f\"‚úÖ Data for {day.strftime('%Y-%m-%d')}: {len(df_day)} rows\")\n","            all_logs.append(df_day)\n","        else:\n","            print(f\"‚ö†Ô∏è No activity on {day.strftime('%Y-%m-%d')}\")\n","    except Exception as e:\n","        print(f\"‚ùå Error on {day.strftime('%Y-%m-%d')}: {e}\")\n","\n","# üì¶ Combine results into single DataFrame\n","if all_logs:\n","    df_usage = pd.concat(all_logs, ignore_index=True)\n","    print(f\"\\n‚úÖ Combined total: {len(df_usage)} rows\")\n","    display(df_usage.head())\n","else:\n","    print(\"‚ö†Ô∏è No usage data collected.\")\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"df1587c0-4b1a-4cc6-ad5b-4cf090666212"},{"cell_type":"code","source":["# List all workspaces you have access to\n","df_workspaces = fabric.list_workspaces()\n","df_workspaces.head()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4d6a126a-8485-476d-8cf3-82758a030b4b"},{"cell_type":"code","source":["#Store all reports across workspaces\n","all_reports = []\n","\n","# Loop through each workspace ID\n","for _, row in df_workspaces.iterrows():\n","    ws_id = row[\"Id\"]\n","    ws_name = row[\"Name\"]\n","\n","    try:\n","        df_reports = fabric.list_reports(workspace=ws_id)\n","        if not df_reports.empty:\n","            df_reports[\"Workspace Name\"] = ws_name  # tag workspace name\n","            all_reports.append(df_reports)\n","            print(f\"‚úÖ Reports found in: {ws_name}\")\n","        else:\n","            print(f\"‚ö†Ô∏è No reports in: {ws_name}\")\n","    except Exception as e:\n","        print(f\"‚ùå Error retrieving from {ws_name}: {e}\")\n","\n","if all_reports:\n","    df_all_reports = pd.concat(all_reports, ignore_index=True)\n","    display(df_all_reports.head())\n","else:\n","    print(\"‚ö†Ô∏è No reports found in any workspace.\")\n","\n","display(df_reports.head())"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"a9be8cf3-6390-43f9-8146-8e4a5ed9109b"},{"cell_type":"code","source":["# Create a list to hold each workspace's reports\n","all_reports = []\n","\n","# Loop through each workspace and append report data\n","for ws_id, ws_name in zip(df_workspaces[\"Id\"], df_workspaces[\"Name\"]):\n","    df_reports = fabric.list_reports(workspace=ws_id)\n","    if not df_reports.empty:\n","        df_reports[\"WorkspaceId\"] = ws_id\n","        df_reports[\"WorkspaceName\"] = ws_name\n","        all_reports.append(df_reports)\n","\n","# Concatenate into one DataFrame\n","df_all_reports = pd.concat(all_reports, ignore_index=True)\n","df_all_reports = df_all_reports[[\"Name\", \"WorkspaceName\"]]\n","\n","\n","# Display the combined DataFrame\n","display(df_all_reports.head())"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"c38798dc-51df-4f1e-8706-63febea23a92"},{"cell_type":"code","source":["df_spark = spark.createDataFrame(df_all_reports)\n","df_spark.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"AdminReports\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4ab4f0d0-a0f2-4ab7-8674-8f37e45b5165"},{"cell_type":"code","source":["# üóìÔ∏è Pull usage for the last 30 days\n","days_back = 90\n","activity_filter = \"viewreport\"\n","usage_logs = []\n","\n","for i in range(days_back):\n","    date = datetime.utcnow() - timedelta(days=i)\n","    start_time = f\"{date.strftime('%Y-%m-%d')}T00:00:00\"\n","    end_time = f\"{date.strftime('%Y-%m-%d')}T23:59:59\"\n","\n","    try:\n","        df_day = admin.list_activity_events(\n","            start_time=start_time,\n","            end_time=end_time,\n","            activity_filter=activity_filter\n","        )\n","        usage_logs.append(df_day)\n","    except:\n","        continue\n","\n","df_usage = pd.concat(usage_logs, ignore_index=True)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8f2ae9bc-4b6c-4d03-b270-9d8715c5fc8e"},{"cell_type":"code","source":["df_usage.head()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cf69fb6b-7cd4-4d7e-bea5-4fda2be7aa2b"},{"cell_type":"code","source":["# Save to csv\n","df_usage.to_csv('/lakehouse/default/' + 'Files/df_usage.csv', index=False)\n","df_usage.columns= [col.replace(\" \", \"_\") for col in df_usage.columns]"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"dc715b10-5bcb-4784-b3c4-f57841a2e385"},{"cell_type":"code","source":["df_spark = spark.createDataFrame(df_usage)\n","df_spark.write.mode(\"overwrite\").format(\"delta\").save(\"Tables/Usage\")\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2738a7b3-1128-4183-a79f-3e63eafe847b"},{"cell_type":"code","source":["df2 = spark.read.format(\"delta\").load(\"Tables/Usage\")\n","# Convert and preview first 5 rows\n","df2.toPandas().head(5)\n","df2.toPandas().shape"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1ded936c-a280-4a42-91b2-c5dc7ad7f514"},{"cell_type":"markdown","source":["https://github.com/microsoft/semantic-link-labs\n","\n","https://tabulareditor.com/learn"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7eca0472-f477-449b-9804-2502da3188e8"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"300bf873-d380-4f73-8685-642a0f911bbd"}],"default_lakehouse":"300bf873-d380-4f73-8685-642a0f911bbd","default_lakehouse_name":"PythonIntro","default_lakehouse_workspace_id":"0ab57829-4ee1-4a0a-8678-6b07f7109f8f"}}},"nbformat":4,"nbformat_minor":5}