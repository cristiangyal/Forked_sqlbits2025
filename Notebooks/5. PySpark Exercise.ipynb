{"cells":[{"cell_type":"markdown","source":["# PySpark Practice Notebook\n","\n","Welcome to the PySpark learner notebook!"],"metadata":{},"id":"c07df350"},{"cell_type":"code","source":["df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"Files/personality_dataset.csv\")\n","# df now is a Spark DataFrame containing CSV data from \"Files/personality_dataset.csv\".\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"8e5648f6-6a6e-4bd5-9718-eec35cfc0e94"},{"cell_type":"code","source":["type(df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"23d8d43c-2023-4c3f-a964-584ad50aeabb"},{"cell_type":"code","source":["# ðŸ‘€ Preview the data\n","# Hint: use .show()\n","df.show()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ce829bb6"},{"cell_type":"code","source":["# ðŸ§¹ Task 1: Filter rows where column 'Drained_after_socializing' = Yes\n","# Hint: use .filter()\n","# Filter rows where Drained_after_socializing = Yes\n","filtered_df = df.filter(df[xxxx] == xxxx)\n","\n","# Display results\n","filtered_df.xxxx()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5b953a80"},{"cell_type":"code","source":["# ðŸ”„ Task 2: Select specific columns (e.g., Friends_circle_size and Post_frequency)\n","# Hint: use .select()\n","selected_df = df.select(xxxx, xxxx)\n","# Display results\n","selected_df.xxxx"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ac663983"},{"cell_type":"code","source":["# ðŸ§® Task 3: Group by a column (e.g., Personality) and count\n","# Hint: use .groupBy().count() and display\n","grouped_df = df.groupBy(xxxxx).xxxx().xxx()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"25f1bbd4"},{"cell_type":"code","source":["# ðŸ’¾ Task 5: Save the transformed DataFrame to parquet\n","# Hint: use .write.parquet()\n","xxxx.write.mode(\"overwrite\").parquet(\"Files/xxxx\")\n","\n","# What type is it?\n","type(xxxx)\n","\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"25f02726"},{"cell_type":"code","source":["# Save as a managed Delta table in Lakehouse\n","xxxxx.write.mode(\"overwrite\").saveAsTable(\"xxxx\")\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d40cc79f-b6fb-41e4-ae6e-37e67639da5f"},{"cell_type":"code","source":["#What do you think this does?\n","\n","\n","df.toPandas().to_parquet('/lakehouse/default/Files/datafile.parquet')"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ac2e7648-f2be-4cc6-8a01-12df0f8588fc"}],"metadata":{"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"kernel_info":{"name":"synapse_pyspark"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"300bf873-d380-4f73-8685-642a0f911bbd"}],"default_lakehouse":"300bf873-d380-4f73-8685-642a0f911bbd","default_lakehouse_name":"PythonIntro","default_lakehouse_workspace_id":"0ab57829-4ee1-4a0a-8678-6b07f7109f8f"}}},"nbformat":4,"nbformat_minor":5}