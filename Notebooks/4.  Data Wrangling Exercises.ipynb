{"cells":[{"cell_type":"markdown","source":["# üß∞ Data Wrangling with pandas ‚Äì Exercises\n","\n","In this notebook, you‚Äôll practise common wrangling tasks using pre-created DataFrames.\n","‚úÖ Tasks include:\n","- Transforming columns\n","- Joining, merging, and appending data\n","- Working with simple and practical examples"],"metadata":{},"id":"1c3369eb"},{"cell_type":"markdown","source":["## üì¶ Step 1: Setup ‚Äì Run this to create sample data"],"metadata":{},"id":"05633ccf"},{"cell_type":"code","source":["import pandas as pd\n","\n","# Employee data\n","df_employees = pd.DataFrame({\n","    'EmployeeID': [1, 2, 3],\n","    'Name': ['Alice', 'Bob', 'Charlie'],\n","    'Department': ['HR', 'IT', 'Finance']\n","})\n","\n","# Salary data\n","df_salaries = pd.DataFrame({\n","    'EmployeeID': [1, 2, 4],\n","    'Salary': [90000, 60000, 55000]\n","})\n","\n","df_employees, df_salaries"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8a57cde7"},{"cell_type":"markdown","source":["## ‚úÇÔ∏è Step 2: Transform Columns"],"metadata":{},"id":"1d265d46"},{"cell_type":"code","source":["# TODO: \n","# 1. Create a new column in df_salaries called 'SalaryBand' (df_salaries['SalaryBand'])\n","# 2. Use pd.cut( on the original salary column) \n","# 3. Define 3 bands: Low (<=55000), Medium (<=60000), High, bins = [, , ], \n","# 4. Define labels = labels = [' ', ' ', ' ']\n","# don't forget your friendly helper\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8364277c"},{"cell_type":"markdown","source":["## üîó Step 3: Join DataFrames (by index)"],"metadata":{},"id":"2d4d0ab3"},{"cell_type":"code","source":["# TODO: Join df_employees and df_salaries using .join()\n","# Hint: Set EmployeeID as index first on both DataFrames, then use join()\n","\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2f8b40df"},{"cell_type":"markdown","source":["## üîÄ Step 4: Merge DataFrames (by column)"],"metadata":{},"id":"434ad2ad"},{"cell_type":"code","source":["# TODO: Merge df_employees and df_salaries using pd.merge()\n","# Hint: Merge on 'EmployeeID' and try both 'inner' and 'left' joins\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"aa024cc7"},{"cell_type":"markdown","source":["## ‚ûï Step 5: Append a New Row"],"metadata":{},"id":"e6260b9a"},{"cell_type":"code","source":["# TODO: Add a new employee (ID 5, Name: Diana, Department: Marketing)\n","# Hint: Use pd.concat() to append a new row DataFrame to df_employees\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f938da33"},{"cell_type":"markdown","source":["## üéØ Bonus Challenge"],"metadata":{},"id":"e15fdc5b"},{"cell_type":"code","source":["# Can you group the merged data by Department and calculate average salary?\n","# Try using .groupby() and .mean()\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d9e1b6da"}],"metadata":{"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"kernel_info":{"name":"synapse_pyspark"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"300bf873-d380-4f73-8685-642a0f911bbd"}],"default_lakehouse":"300bf873-d380-4f73-8685-642a0f911bbd","default_lakehouse_name":"PythonIntro","default_lakehouse_workspace_id":"0ab57829-4ee1-4a0a-8678-6b07f7109f8f"}}},"nbformat":4,"nbformat_minor":5}