{"cells":[{"cell_type":"markdown","source":["# üß∞ Data Wrangling with pandas ‚Äì Exercises\n","\n","In this notebook, you‚Äôll practise common wrangling tasks using pre-created DataFrames.\n","‚úÖ Tasks include:\n","- Transforming columns\n","- Joining, merging, and appending data\n","- Working with simple and practical examples"],"metadata":{},"id":"1c3369eb"},{"cell_type":"markdown","source":["## üì¶ Step 1: Setup ‚Äì Run this to create sample data"],"metadata":{},"id":"05633ccf"},{"cell_type":"code","source":["import pandas as pd\n","\n","# Employee data\n","df_employees = pd.DataFrame({\n","    'EmployeeID': [1, 2, 3],\n","    'Name': ['Alice', 'Bob', 'Charlie'],\n","    'Department': ['HR', 'IT', 'Finance']\n","})\n","\n","# Salary data\n","df_salaries = pd.DataFrame({\n","    'EmployeeID': [1, 2, 4],\n","    'Salary': [90000, 60000, 55000]\n","})\n","\n","df_employees, df_salaries"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"56ce1efc-b96c-44ec-88b3-f310c7aab827","normalized_state":"finished","queued_time":"2025-06-03T15:00:29.5704008Z","session_start_time":null,"execution_start_time":"2025-06-03T15:00:29.5715521Z","execution_finish_time":"2025-06-03T15:00:29.8344327Z","parent_msg_id":"08523e27-7cb5-4828-9b51-cda395bfe494"},"text/plain":"StatementMeta(, 56ce1efc-b96c-44ec-88b3-f310c7aab827, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"(   EmployeeID     Name Department\n 0           1    Alice         HR\n 1           2      Bob         IT\n 2           3  Charlie    Finance,\n    EmployeeID  Salary\n 0           1   90000\n 1           2   60000\n 2           4   55000)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8a57cde7"},{"cell_type":"markdown","source":["## ‚úÇÔ∏è Step 2: Transform Columns"],"metadata":{},"id":"1d265d46"},{"cell_type":"code","source":["# TODO: Create a new column in df_salaries called 'SalaryBand'\n","# Hint: Use pd.cut() and define 3 bands: Low (<=55000), Medium (<=60000), High\n","# help(pd.cut)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"56ce1efc-b96c-44ec-88b3-f310c7aab827","normalized_state":"finished","queued_time":"2025-06-03T15:01:21.2768939Z","session_start_time":null,"execution_start_time":"2025-06-03T15:01:21.2779351Z","execution_finish_time":"2025-06-03T15:01:21.6052085Z","parent_msg_id":"3d4f0d79-0e37-4231-9fbe-209fb8b32c96"},"text/plain":"StatementMeta(, 56ce1efc-b96c-44ec-88b3-f310c7aab827, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Help on function cut in module pandas.core.reshape.tile:\n\ncut(x, bins, right: 'bool' = True, labels=None, retbins: 'bool' = False, precision: 'int' = 3, include_lowest: 'bool' = False, duplicates: 'str' = 'raise', ordered: 'bool' = True)\n    Bin values into discrete intervals.\n    \n    Use `cut` when you need to segment and sort data values into bins. This\n    function is also useful for going from a continuous variable to a\n    categorical variable. For example, `cut` could convert ages to groups of\n    age ranges. Supports binning into an equal number of bins, or a\n    pre-specified array of bins.\n    \n    Parameters\n    ----------\n    x : array-like\n        The input array to be binned. Must be 1-dimensional.\n    bins : int, sequence of scalars, or IntervalIndex\n        The criteria to bin by.\n    \n        * int : Defines the number of equal-width bins in the range of `x`. The\n          range of `x` is extended by .1% on each side to include the minimum\n          and maximum values of `x`.\n        * sequence of scalars : Defines the bin edges allowing for non-uniform\n          width. No extension of the range of `x` is done.\n        * IntervalIndex : Defines the exact bins to be used. Note that\n          IntervalIndex for `bins` must be non-overlapping.\n    \n    right : bool, default True\n        Indicates whether `bins` includes the rightmost edge or not. If\n        ``right == True`` (the default), then the `bins` ``[1, 2, 3, 4]``\n        indicate (1,2], (2,3], (3,4]. This argument is ignored when\n        `bins` is an IntervalIndex.\n    labels : array or False, default None\n        Specifies the labels for the returned bins. Must be the same length as\n        the resulting bins. If False, returns only integer indicators of the\n        bins. This affects the type of the output container (see below).\n        This argument is ignored when `bins` is an IntervalIndex. If True,\n        raises an error. When `ordered=False`, labels must be provided.\n    retbins : bool, default False\n        Whether to return the bins or not. Useful when bins is provided\n        as a scalar.\n    precision : int, default 3\n        The precision at which to store and display the bins labels.\n    include_lowest : bool, default False\n        Whether the first interval should be left-inclusive or not.\n    duplicates : {default 'raise', 'drop'}, optional\n        If bin edges are not unique, raise ValueError or drop non-uniques.\n    ordered : bool, default True\n        Whether the labels are ordered or not. Applies to returned types\n        Categorical and Series (with Categorical dtype). If True,\n        the resulting categorical will be ordered. If False, the resulting\n        categorical will be unordered (labels must be provided).\n    \n    Returns\n    -------\n    out : Categorical, Series, or ndarray\n        An array-like object representing the respective bin for each value\n        of `x`. The type depends on the value of `labels`.\n    \n        * None (default) : returns a Series for Series `x` or a\n          Categorical for all other inputs. The values stored within\n          are Interval dtype.\n    \n        * sequence of scalars : returns a Series for Series `x` or a\n          Categorical for all other inputs. The values stored within\n          are whatever the type in the sequence is.\n    \n        * False : returns an ndarray of integers.\n    \n    bins : numpy.ndarray or IntervalIndex.\n        The computed or specified bins. Only returned when `retbins=True`.\n        For scalar or sequence `bins`, this is an ndarray with the computed\n        bins. If set `duplicates=drop`, `bins` will drop non-unique bin. For\n        an IntervalIndex `bins`, this is equal to `bins`.\n    \n    See Also\n    --------\n    qcut : Discretize variable into equal-sized buckets based on rank\n        or based on sample quantiles.\n    Categorical : Array type for storing data that come from a\n        fixed set of values.\n    Series : One-dimensional array with axis labels (including time series).\n    IntervalIndex : Immutable Index implementing an ordered, sliceable set.\n    \n    Notes\n    -----\n    Any NA values will be NA in the result. Out of bounds values will be NA in\n    the resulting Series or Categorical object.\n    \n    Reference :ref:`the user guide <reshaping.tile.cut>` for more examples.\n    \n    Examples\n    --------\n    Discretize into three equal-sized bins.\n    \n    >>> pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3)\n    ... # doctest: +ELLIPSIS\n    [(0.994, 3.0], (5.0, 7.0], (3.0, 5.0], (3.0, 5.0], (5.0, 7.0], ...\n    Categories (3, interval[float64, right]): [(0.994, 3.0] < (3.0, 5.0] ...\n    \n    >>> pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3, retbins=True)\n    ... # doctest: +ELLIPSIS\n    ([(0.994, 3.0], (5.0, 7.0], (3.0, 5.0], (3.0, 5.0], (5.0, 7.0], ...\n    Categories (3, interval[float64, right]): [(0.994, 3.0] < (3.0, 5.0] ...\n    array([0.994, 3.   , 5.   , 7.   ]))\n    \n    Discovers the same bins, but assign them specific labels. Notice that\n    the returned Categorical's categories are `labels` and is ordered.\n    \n    >>> pd.cut(np.array([1, 7, 5, 4, 6, 3]),\n    ...        3, labels=[\"bad\", \"medium\", \"good\"])\n    ['bad', 'good', 'medium', 'medium', 'good', 'bad']\n    Categories (3, object): ['bad' < 'medium' < 'good']\n    \n    ``ordered=False`` will result in unordered categories when labels are passed.\n    This parameter can be used to allow non-unique labels:\n    \n    >>> pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,\n    ...        labels=[\"B\", \"A\", \"B\"], ordered=False)\n    ['B', 'B', 'A', 'A', 'B', 'B']\n    Categories (2, object): ['A', 'B']\n    \n    ``labels=False`` implies you just want the bins back.\n    \n    >>> pd.cut([0, 1, 1, 2], bins=4, labels=False)\n    array([0, 1, 1, 3])\n    \n    Passing a Series as an input returns a Series with categorical dtype:\n    \n    >>> s = pd.Series(np.array([2, 4, 6, 8, 10]),\n    ...               index=['a', 'b', 'c', 'd', 'e'])\n    >>> pd.cut(s, 3)\n    ... # doctest: +ELLIPSIS\n    a    (1.992, 4.667]\n    b    (1.992, 4.667]\n    c    (4.667, 7.333]\n    d     (7.333, 10.0]\n    e     (7.333, 10.0]\n    dtype: category\n    Categories (3, interval[float64, right]): [(1.992, 4.667] < (4.667, ...\n    \n    Passing a Series as an input returns a Series with mapping value.\n    It is used to map numerically to intervals based on bins.\n    \n    >>> s = pd.Series(np.array([2, 4, 6, 8, 10]),\n    ...               index=['a', 'b', 'c', 'd', 'e'])\n    >>> pd.cut(s, [0, 2, 4, 6, 8, 10], labels=False, retbins=True, right=False)\n    ... # doctest: +ELLIPSIS\n    (a    1.0\n     b    2.0\n     c    3.0\n     d    4.0\n     e    NaN\n     dtype: float64,\n     array([ 0,  2,  4,  6,  8, 10]))\n    \n    Use `drop` optional when bins is not unique\n    \n    >>> pd.cut(s, [0, 2, 4, 6, 10, 10], labels=False, retbins=True,\n    ...        right=False, duplicates='drop')\n    ... # doctest: +ELLIPSIS\n    (a    1.0\n     b    2.0\n     c    3.0\n     d    3.0\n     e    NaN\n     dtype: float64,\n     array([ 0,  2,  4,  6, 10]))\n    \n    Passing an IntervalIndex for `bins` results in those categories exactly.\n    Notice that values not covered by the IntervalIndex are set to NaN. 0\n    is to the left of the first bin (which is closed on the right), and 1.5\n    falls between two bins.\n    \n    >>> bins = pd.IntervalIndex.from_tuples([(0, 1), (2, 3), (4, 5)])\n    >>> pd.cut([0, 0.5, 1.5, 2.5, 4.5], bins)\n    [NaN, (0.0, 1.0], NaN, (2.0, 3.0], (4.0, 5.0]]\n    Categories (3, interval[int64, right]): [(0, 1] < (2, 3] < (4, 5]]\n\n"]}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8364277c"},{"cell_type":"markdown","source":["## üîó Step 3: Join DataFrames (by index)"],"metadata":{},"id":"2d4d0ab3"},{"cell_type":"code","source":["# TODO: Join df_employees and df_salaries using .join()\n","# Hint: Set EmployeeID as index first on both DataFrames, then use join()\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2f8b40df"},{"cell_type":"markdown","source":["## üîÄ Step 4: Merge DataFrames (by column)"],"metadata":{},"id":"434ad2ad"},{"cell_type":"code","source":["# TODO: Merge df_employees and df_salaries using pd.merge()\n","# Hint: Merge on 'EmployeeID' and try both 'inner' and 'left' joins\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"aa024cc7"},{"cell_type":"markdown","source":["## ‚ûï Step 5: Append a New Row"],"metadata":{},"id":"e6260b9a"},{"cell_type":"code","source":["# TODO: Add a new employee (ID 5, Name: Diana, Department: Marketing)\n","# Hint: Use pd.concat() to append a new row DataFrame to df_employees\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f938da33"},{"cell_type":"markdown","source":["## üéØ Bonus Challenge"],"metadata":{},"id":"e15fdc5b"},{"cell_type":"code","source":["# Can you group the merged data by Department and calculate average salary?\n","# Try using .groupby() and .mean()\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d9e1b6da"}],"metadata":{"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"kernel_info":{"name":"synapse_pyspark"},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"300bf873-d380-4f73-8685-642a0f911bbd"}],"default_lakehouse":"300bf873-d380-4f73-8685-642a0f911bbd","default_lakehouse_name":"PythonIntro","default_lakehouse_workspace_id":"0ab57829-4ee1-4a0a-8678-6b07f7109f8f"}}},"nbformat":4,"nbformat_minor":5}